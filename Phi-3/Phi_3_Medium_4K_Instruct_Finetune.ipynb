{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiiwee/opengen/blob/master/Phi-3/Phi_3_Medium_4K_Instruct_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"align-center\">\n",
        "  <a href=\"https://www.fontys.nl/\"><img src=\"https://www.fontys.nl/static/design/FA845701-BD71-466E-9B3D-38580DFAD5B4-fsm/images/logo-inverted@2x.png\" width=\"120\"></a>\n",
        "  <!-- <img src=\"https://i.imgur.com/zyfbV3r.png\" width=\"20\">\n",
        "  <a href=\"https://www.arise-biodiversity.nl/\"><img src=\"https://i.imgur.com/fwGepON.png\" width=\"200\"></a>\n",
        "  <img src=\"https://i.imgur.com/zyfbV3r.png\" width=\"20\">\n",
        "  <a href=\"https://diopsis.eu/\"><img src=\"https://i.imgur.com/e6nutxp.png\" width=\"180\"></a> -->\n",
        "</div>\n",
        "\n",
        "# **In this notebook we will train a Phi-3 Medium 4K Instruct model on a custom dataset using the Unsloth framework**\n",
        "\n",
        "---\n",
        "\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/kiiwee/opengen)\n",
        "\n",
        "<a href=\"https://github.com/facebookresearch/detectron2\"><img src=\"https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png\" width=\"80\"></a>"
      ],
      "metadata": {
        "id": "418R3ZwNe3dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIO-o0gmv2cI",
        "outputId": "d2048871-52c9-4755-cb71-a0c4a429b6bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First we install the unsloth library:"
      ],
      "metadata": {
        "id": "hCC3-SiI305W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And load the base model to be fine-tuned:"
      ],
      "metadata": {
        "id": "b33gvz1J39k0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "c2c1c4ef3ead4fa2bd2f5dea7ece12fb",
            "465188f321e7492ab924819325ddef7a",
            "8f1cd6b2bb3a454c96767f91fb0dad0f",
            "f591a6680b69466aa5ec3db8914cd680",
            "756be3bdfa1b4f44ba61e770971c79f3",
            "33a1900f2b82424aab48c5da6837b67f",
            "1dbdd06e729a4d4ab3a7277ebf9ea622",
            "ad4872f67c2d4055890591b72897f30d",
            "6eec753bdb49485e91087bb453a1e262",
            "2843888970134722bc502878b497e9c6",
            "3a02131532c540079fe1684f70583d18"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "84a74024-2720-4a09-c3fb-ce077600630f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2c1c4ef3ead4fa2bd2f5dea7ece12fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # RoPE Scaling internally\n",
        "dtype = None # Auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We now add LoRA adapters so we only need to update 1 to 10% of all parameters:"
      ],
      "metadata": {
        "id": "SXd9bTZd1aaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d110c5e8-f495-4f2a-f608-d4661598d5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.6 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # 0 is optimized\n",
        "    bias = \"none\",    # \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next we load the train and validation dataset from HuggingFace:"
      ],
      "metadata": {
        "id": "vITh0KVJ10qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"kalinkov/tailwindcss_components\", split = \"train\")\n",
        "eval_dataset = load_dataset(\"kalinkov/tailwindcss_components\", split = \"validation\")"
      ],
      "metadata": {
        "id": "Z_5d0sjwxX0Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And we setup the trainer parameters:"
      ],
      "metadata": {
        "id": "idAEIeSQ3xdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "95_Nn-89DhsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f06806-fc18-4d66-b6d2-e407dfcd06a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 0,\n",
        "        num_train_epochs=1,\n",
        "        # eval params\n",
        "        fp16_full_eval = True,\n",
        "        per_device_eval_batch_size = 2,\n",
        "        eval_accumulation_steps = 4,\n",
        "        evaluation_strategy = \"steps\",\n",
        "        eval_steps = 10,\n",
        "        save_strategy = \"steps\",\n",
        "        save_steps = 10,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"/content/drive/MyDrive/data_challenge/Evaluation_training\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61fac5d-6596-4237-9ade-02206f22853b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.564 GB.\n",
            "7.504 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We initiate the initial 1 epoch training:"
      ],
      "metadata": {
        "id": "H7OIj0Ak4UIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36a8592b-a957-4870-96e3-cefb9bd68d22",
        "collapsed": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,683 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 210\n",
            " \"-____-\"     Number of trainable parameters = 65,536,000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 53/210 1:02:23 < 3:12:04, 0.01 it/s, Epoch 0.25/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.897400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.810100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.891500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.869300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.805800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.803600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.693200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.671100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.757700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.590500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.651900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.679100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.509900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.608900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.580500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.657500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.499800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.567500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.549400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.517700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.529600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.588200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.553600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.510200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.480700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.563600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.545800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.602400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.362800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.504800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.540800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.562600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.468400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.553000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.507200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.538200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.460900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 4:17:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.897400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.810100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.891500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.869300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.805800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.803600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.693200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.671100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.757700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.590500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.651900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.679100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.509900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.608900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.580500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.657500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.499800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.567500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.549400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.517700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.529600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.588200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.553600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.510200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.480700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.563600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.545800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.602400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.362800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.504800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.540800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.562600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.468400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.553000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.507200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.538200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.460900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.488100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.556600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.633200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.492300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.454700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.516500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.461400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.402800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.466500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.750700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.413100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.522900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.504800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.429500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.531800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.525700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.532600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.491500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.391500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.516400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.430700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.483300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.435400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.387600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.319800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.454300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.508600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.461900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.446200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.369000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.478900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.549900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.532400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.449100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.425700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.422400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.338300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.409200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.507200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.388800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.354600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.523000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.541800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.457900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.414500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.303700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.482100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.390800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.523500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.497000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.422700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.471400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.416400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.454000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.392200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.394500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.463400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.463000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.517600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.482000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.307500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.418500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.637400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.349900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.469400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.526700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.416000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.403200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.388600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.623700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.430900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.405300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.432200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.366800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.421800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.281100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.434100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.404200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.550400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.426500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.332700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.471700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.476500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.400100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.496400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.502300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.498700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.386000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.436400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.289600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.341700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.431800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.430300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.384000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.452700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.348200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.527100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.347500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.373100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.458900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.336700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.507100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.401300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.442100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.562100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.383900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.386100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.506800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.440200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.423200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.423700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.431200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.392400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.433600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.353700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.408800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.436500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.346200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.447900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.475500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.449700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.394500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.445100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.400600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.418500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.536900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.493000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.316500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "w-5MnFWetBLO",
        "outputId": "88f1965c-c381-4041-da47-fc7f667c8f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,683 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 210\n",
            " \"-____-\"     Number of trainable parameters = 65,536,000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 52:28, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.686100</td>\n",
              "      <td>0.730386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.516000</td>\n",
              "      <td>0.647077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.553700</td>\n",
              "      <td>0.609974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.547600</td>\n",
              "      <td>0.587576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.462400</td>\n",
              "      <td>0.569451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.522200</td>\n",
              "      <td>0.553456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.542800</td>\n",
              "      <td>0.538971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.593900</td>\n",
              "      <td>0.527049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.492900</td>\n",
              "      <td>0.519172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.424100</td>\n",
              "      <td>0.514378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.306800</td>\n",
              "      <td>0.505913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.420500</td>\n",
              "      <td>0.499686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.495856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.627700</td>\n",
              "      <td>0.492763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.407300</td>\n",
              "      <td>0.489330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.505000</td>\n",
              "      <td>0.484153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.430700</td>\n",
              "      <td>0.482501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.393000</td>\n",
              "      <td>0.481835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.356400</td>\n",
              "      <td>0.479189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.463800</td>\n",
              "      <td>0.477668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.319600</td>\n",
              "      <td>0.477261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Followed by 2 more epochs:"
      ],
      "metadata": {
        "id": "z0y0pGK14eQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 0,\n",
        "        num_train_epochs=3,\n",
        "        # eval params\n",
        "        fp16_full_eval = True,\n",
        "        per_device_eval_batch_size = 2,\n",
        "        eval_accumulation_steps = 4,\n",
        "        evaluation_strategy = \"steps\",\n",
        "        eval_steps = 10,\n",
        "        save_strategy = \"steps\",\n",
        "        save_steps = 10,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"/content/drive/MyDrive/data_challenge/Evaluation_training\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdD-dpUpWEo0",
        "outputId": "883a2455-b636-45f9-d23e-81833f28e738"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train(resume_from_checkpoint = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "9OZzt8pxVy2T",
        "outputId": "1de9f8bb-e13a-4108-ca99-e2754625ae42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,683 | Num Epochs = 3\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 630\n",
            " \"-____-\"     Number of trainable parameters = 65,536,000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 52:13, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.343300</td>\n",
              "      <td>0.451122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.258500</td>\n",
              "      <td>0.455547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.304900</td>\n",
              "      <td>0.452578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.252300</td>\n",
              "      <td>0.454047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.390100</td>\n",
              "      <td>0.451694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.255100</td>\n",
              "      <td>0.449968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.319600</td>\n",
              "      <td>0.446997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.382600</td>\n",
              "      <td>0.445371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.445946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.291500</td>\n",
              "      <td>0.447992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.324400</td>\n",
              "      <td>0.442695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.241300</td>\n",
              "      <td>0.444899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.275400</td>\n",
              "      <td>0.440925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.440171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.228400</td>\n",
              "      <td>0.438705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.327500</td>\n",
              "      <td>0.438580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.381300</td>\n",
              "      <td>0.439315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.291400</td>\n",
              "      <td>0.438290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.271100</td>\n",
              "      <td>0.436896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.317100</td>\n",
              "      <td>0.436530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.436747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We look at the training results throughout the fine-tuning process:"
      ],
      "metadata": {
        "id": "GMQhYvgp4jAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "loss_history = pd.DataFrame(trainer.state.log_history)"
      ],
      "metadata": {
        "id": "lYVBkcvW0-EL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history[loss_history[\"step\"] % 10 == 0][30:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "xf--UnMs1ET6",
        "outputId": "2c74133f-c9b1-4b80-faec-25dc0a12214c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        epoch  grad_norm  learning_rate    loss  step  eval_loss  \\\n",
              "174  0.760095   0.171091       0.000049  0.5050   160        NaN   \n",
              "175  0.760095        NaN            NaN     NaN   160   0.484153   \n",
              "185  0.807601   0.159732       0.000039  0.4307   170        NaN   \n",
              "186  0.807601        NaN            NaN     NaN   170   0.482501   \n",
              "196  0.855107   0.199525       0.000029  0.3930   180        NaN   \n",
              "197  0.855107        NaN            NaN     NaN   180   0.481835   \n",
              "207  0.902613   0.150071       0.000020  0.3564   190        NaN   \n",
              "208  0.902613        NaN            NaN     NaN   190   0.479189   \n",
              "218  0.950119   0.174251       0.000010  0.4638   200        NaN   \n",
              "219  0.950119        NaN            NaN     NaN   200   0.477668   \n",
              "229  0.997625   0.177665       0.000000  0.3196   210        NaN   \n",
              "230  0.997625        NaN            NaN     NaN   210   0.477261   \n",
              "240  1.047506   0.202559       0.000096  0.4366   220        NaN   \n",
              "241  1.047506        NaN            NaN     NaN   220   0.480933   \n",
              "251  1.095012   0.238655       0.000092  0.3515   230        NaN   \n",
              "252  1.095012        NaN            NaN     NaN   230   0.480817   \n",
              "262  1.142518   0.231712       0.000087  0.3419   240        NaN   \n",
              "263  1.142518        NaN            NaN     NaN   240   0.480275   \n",
              "273  1.190024   0.262130       0.000082  0.3430   250        NaN   \n",
              "274  1.190024        NaN            NaN     NaN   250   0.479066   \n",
              "\n",
              "     eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
              "174           NaN                      NaN                    NaN   \n",
              "175       62.6687                    3.191                  1.596   \n",
              "185           NaN                      NaN                    NaN   \n",
              "186       62.4476                    3.203                  1.601   \n",
              "196           NaN                      NaN                    NaN   \n",
              "197       62.6386                    3.193                  1.596   \n",
              "207           NaN                      NaN                    NaN   \n",
              "208       62.6743                    3.191                  1.596   \n",
              "218           NaN                      NaN                    NaN   \n",
              "219       62.7070                    3.189                  1.595   \n",
              "229           NaN                      NaN                    NaN   \n",
              "230       62.5034                    3.200                  1.600   \n",
              "240           NaN                      NaN                    NaN   \n",
              "241       62.6192                    3.194                  1.597   \n",
              "251           NaN                      NaN                    NaN   \n",
              "252       62.6441                    3.193                  1.596   \n",
              "262           NaN                      NaN                    NaN   \n",
              "263       62.7238                    3.189                  1.594   \n",
              "273           NaN                      NaN                    NaN   \n",
              "274       62.6716                    3.191                  1.596   \n",
              "\n",
              "     train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "174            NaN                       NaN                     NaN   \n",
              "175            NaN                       NaN                     NaN   \n",
              "185            NaN                       NaN                     NaN   \n",
              "186            NaN                       NaN                     NaN   \n",
              "196            NaN                       NaN                     NaN   \n",
              "197            NaN                       NaN                     NaN   \n",
              "207            NaN                       NaN                     NaN   \n",
              "208            NaN                       NaN                     NaN   \n",
              "218            NaN                       NaN                     NaN   \n",
              "219            NaN                       NaN                     NaN   \n",
              "229            NaN                       NaN                     NaN   \n",
              "230            NaN                       NaN                     NaN   \n",
              "240            NaN                       NaN                     NaN   \n",
              "241            NaN                       NaN                     NaN   \n",
              "251            NaN                       NaN                     NaN   \n",
              "252            NaN                       NaN                     NaN   \n",
              "262            NaN                       NaN                     NaN   \n",
              "263            NaN                       NaN                     NaN   \n",
              "273            NaN                       NaN                     NaN   \n",
              "274            NaN                       NaN                     NaN   \n",
              "\n",
              "     total_flos  train_loss  \n",
              "174         NaN         NaN  \n",
              "175         NaN         NaN  \n",
              "185         NaN         NaN  \n",
              "186         NaN         NaN  \n",
              "196         NaN         NaN  \n",
              "197         NaN         NaN  \n",
              "207         NaN         NaN  \n",
              "208         NaN         NaN  \n",
              "218         NaN         NaN  \n",
              "219         NaN         NaN  \n",
              "229         NaN         NaN  \n",
              "230         NaN         NaN  \n",
              "240         NaN         NaN  \n",
              "241         NaN         NaN  \n",
              "251         NaN         NaN  \n",
              "252         NaN         NaN  \n",
              "262         NaN         NaN  \n",
              "263         NaN         NaN  \n",
              "273         NaN         NaN  \n",
              "274         NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2befa9f-9afb-481e-912f-6efbd5188b18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>grad_norm</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>loss</th>\n",
              "      <th>step</th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_runtime</th>\n",
              "      <th>eval_samples_per_second</th>\n",
              "      <th>eval_steps_per_second</th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>total_flos</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>0.760095</td>\n",
              "      <td>0.171091</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.5050</td>\n",
              "      <td>160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>0.760095</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>160</td>\n",
              "      <td>0.484153</td>\n",
              "      <td>62.6687</td>\n",
              "      <td>3.191</td>\n",
              "      <td>1.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>0.807601</td>\n",
              "      <td>0.159732</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.4307</td>\n",
              "      <td>170</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>0.807601</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>170</td>\n",
              "      <td>0.482501</td>\n",
              "      <td>62.4476</td>\n",
              "      <td>3.203</td>\n",
              "      <td>1.601</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.855107</td>\n",
              "      <td>0.199525</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.3930</td>\n",
              "      <td>180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.855107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>180</td>\n",
              "      <td>0.481835</td>\n",
              "      <td>62.6386</td>\n",
              "      <td>3.193</td>\n",
              "      <td>1.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.902613</td>\n",
              "      <td>0.150071</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>0.902613</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>190</td>\n",
              "      <td>0.479189</td>\n",
              "      <td>62.6743</td>\n",
              "      <td>3.191</td>\n",
              "      <td>1.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>0.950119</td>\n",
              "      <td>0.174251</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.4638</td>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>0.950119</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>0.477668</td>\n",
              "      <td>62.7070</td>\n",
              "      <td>3.189</td>\n",
              "      <td>1.595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>0.997625</td>\n",
              "      <td>0.177665</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>0.997625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>210</td>\n",
              "      <td>0.477261</td>\n",
              "      <td>62.5034</td>\n",
              "      <td>3.200</td>\n",
              "      <td>1.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>1.047506</td>\n",
              "      <td>0.202559</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>220</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>1.047506</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>220</td>\n",
              "      <td>0.480933</td>\n",
              "      <td>62.6192</td>\n",
              "      <td>3.194</td>\n",
              "      <td>1.597</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>1.095012</td>\n",
              "      <td>0.238655</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.3515</td>\n",
              "      <td>230</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>1.095012</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230</td>\n",
              "      <td>0.480817</td>\n",
              "      <td>62.6441</td>\n",
              "      <td>3.193</td>\n",
              "      <td>1.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>1.142518</td>\n",
              "      <td>0.231712</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.3419</td>\n",
              "      <td>240</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>1.142518</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>240</td>\n",
              "      <td>0.480275</td>\n",
              "      <td>62.7238</td>\n",
              "      <td>3.189</td>\n",
              "      <td>1.594</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>1.190024</td>\n",
              "      <td>0.262130</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.3430</td>\n",
              "      <td>250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>1.190024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>250</td>\n",
              "      <td>0.479066</td>\n",
              "      <td>62.6716</td>\n",
              "      <td>3.191</td>\n",
              "      <td>1.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2befa9f-9afb-481e-912f-6efbd5188b18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2befa9f-9afb-481e-912f-6efbd5188b18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2befa9f-9afb-481e-912f-6efbd5188b18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eaaa8365-f57e-4991-a854-977babfa452a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eaaa8365-f57e-4991-a854-977babfa452a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eaaa8365-f57e-4991-a854-977babfa452a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"loss_history[loss_history[\\\"step\\\"] % 10 == 0][30:50]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14101470127539378,\n        \"min\": 0.7600950118764845,\n        \"max\": 1.190023752969121,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.1425178147268409,\n          0.8076009501187649,\n          0.997624703087886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grad_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03707712622864061,\n        \"min\": 0.15007059276103973,\n        \"max\": 0.2621299922466278,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.23171205818653107,\n          0.15973232686519623,\n          0.1776648759841919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.6284439134743556e-05,\n        \"min\": 0.0,\n        \"max\": 9.638554216867471e-05,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8.674698795180724e-05,\n          3.9024390243902444e-05,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06184770273286902,\n        \"min\": 0.3196,\n        \"max\": 0.505,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3419,\n          0.4307,\n          0.3196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 160,\n        \"max\": 250,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          240,\n          170,\n          210\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021496723896754673,\n        \"min\": 0.477260947227478,\n        \"max\": 0.48415306210517883,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48027503490448,\n          0.4825010597705841,\n          0.477260947227478\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08794229231591427,\n        \"min\": 62.4476,\n        \"max\": 62.7238,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          62.7238,\n          62.4476,\n          62.5034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004623610902506595,\n        \"min\": 3.189,\n        \"max\": 3.203,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.191,\n          3.203,\n          3.194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002162817093001097,\n        \"min\": 1.594,\n        \"max\": 1.601,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.596,\n          1.601,\n          1.594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_flos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history.to_csv('/content/drive/MyDrive/data_challenge/Evaluation_training/loss_history.csv')"
      ],
      "metadata": {
        "id": "_VaLUDguwUSH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the desired checkpoint:"
      ],
      "metadata": {
        "id": "_ny8HOkI5fD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(resume_from_checkpoint='/content/drive/MyDrive/data_challenge/Evaluation_training/checkpoint-210/')"
      ],
      "metadata": {
        "id": "zV_226og5j7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f59251d-686e-4a19-e65f-0c1cf3203caa"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15551.9819 seconds used for training.\n",
            "259.2 minutes used for training.\n",
            "Peak reserved memory = 9.92 GB.\n",
            "Peak reserved memory for training = 2.416 GB.\n",
            "Peak reserved memory % of max memory = 67.263 %.\n",
            "Peak reserved memory for training % of max memory = 16.382 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the finetuned model"
      ],
      "metadata": {
        "id": "uMuVrWbjAzhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"/content/drive/MyDrive/data_challenge/LoRa/lora_model\") # Local saving\n",
        "model.push_to_hub(\"kalinkov/phi3_lora_model\", token = \"hf_...\") # Online saving"
      ],
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf2a67f-73fa-4c2f-abfb-dd709a3d5b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/kalinkov/phi3_lora_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "\n",
        "Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K."
      ],
      "metadata": {
        "id": "TCv4vXHd61i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if True: model.push_to_hub_gguf(\"kalinkov/Phi3_tailwindcss\", tokenizer, quantization_method = \"q4_k_m\", token = \"hf_...\")"
      ],
      "metadata": {
        "id": "FqfebeAdT073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bec7b21e53b34788b1af1fc6daf22461",
            "071b9704be194a6db44623ea6d5c9fcd",
            "2731a96fb7344325a0576febcb8576b5",
            "adff0e80933c482d8fa09fbfdb64f000",
            "b7b48e0e692340d7b045172d2ea49541",
            "296157256bc1431f98b1c1b1245b7912",
            "fae14ad95cc54ee9903cc3b6e991023c",
            "5eb389cd0cba4b018cfa1cde3a86929f",
            "e9b9e824445f4f82a61c5d058539c800",
            "4762e7e5b5334353850132ae6b0e020b",
            "d2b374598612450fb9d0f8facd5108d0",
            "3233866a7b8c4a7abb983b94c87b2c5d",
            "83424c5d88ab4f98a7b353baf3e31b75",
            "cd1757d864d5469b9cc853a207efec85",
            "681b0b39fe634b6b9b0edc5515b4699a",
            "d1ef53f38bc14718ad89e85926debd40",
            "d8c0b4133bc7474ca474cdb709d1a7d5",
            "55b6ceff71524f70b437e212893b85a0",
            "cf5a0ef3697f45af86eee683dd05af4b",
            "170335cc3c5345f3a8ad2d75cb436649",
            "ec2638df20f54e8b9d173fa082c252b1",
            "3b4f15e869904922b4998d1984ef4f01"
          ]
        },
        "outputId": "6b130b35-e610-4a90-a390-b23b5c020887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Will remove a cached repo with size 1.2K\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 34.36 out of 50.99 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:15<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Extending kalinkov/Phi3_tailwindcss/tokenizer.model with added_tokens.json.\n",
            "Originally tokenizer.model is of size (32000).\n",
            "But we need to extend to sentencepiece vocab size (32011).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GUUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at kalinkov/Phi3_tailwindcss into f16 GGUF format.\n",
            "The output location will be ./kalinkov/Phi3_tailwindcss/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: Phi3_tailwindcss\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 4096\n",
            "INFO:hf-to-gguf:gguf: embedding length = 5120\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 17920\n",
            "INFO:hf-to-gguf:gguf: head count = 40\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 10\n",
            "INFO:hf-to-gguf:gguf: rope theta = 10000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 32000\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 32009\n",
            "INFO:gguf.vocab:Setting add_bos_token to False\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
            "' + message['content'] + '<|end|>' + '\n",
            "' + '<|assistant|>' + '\n",
            "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
            "'}}{% endif %}{% endfor %}\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {5120, 32064}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00005-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.35.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00006-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {5120, 32064}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.36.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_norm.weight,     torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_down.weight,      torch.float16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_gate.weight,      torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_up.weight,        torch.float16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_norm.weight,      torch.float16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_k.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_output.weight,   torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_q.weight,        torch.float16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_v.weight,        torch.float16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {5120}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:kalinkov/Phi3_tailwindcss/unsloth.F16.gguf: n_tensors = 363, total_size = 27.9G\n",
            "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27.9G/27.9G [03:26<00:00, 135Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported.\n",
            "Unsloth: Conversion completed! Output location: ./kalinkov/Phi3_tailwindcss/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3216 (a818f302)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './kalinkov/Phi3_tailwindcss/unsloth.F16.gguf' to './kalinkov/Phi3_tailwindcss/unsloth.Q4_K_M.gguf' as Q4_K_M using 16 threads\n",
            "llama_model_loader: loaded meta data with 26 key-value pairs and 363 tensors from ./kalinkov/Phi3_tailwindcss/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi3_tailwindcss\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 17920\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 10\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32064\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 32009\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
            "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type  f16:  282 tensors\n",
            "[   1/ 363]                    token_embd.weight - [ 5120, 32064,     1,     1], type =    f16, converting to q4_K .. size =   313.12 MiB ->    88.07 MiB\n",
            "[   2/ 363]               blk.0.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   3/ 363]                blk.0.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[   4/ 363]                blk.0.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[   5/ 363]                  blk.0.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[   6/ 363]                blk.0.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   7/ 363]                  blk.0.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[   8/ 363]             blk.0.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   9/ 363]                  blk.0.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  10/ 363]                  blk.0.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  11/ 363]               blk.1.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  12/ 363]                blk.1.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  13/ 363]                blk.1.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  14/ 363]                  blk.1.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  15/ 363]                blk.1.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  16/ 363]                  blk.1.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  17/ 363]             blk.1.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  18/ 363]                  blk.1.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  19/ 363]                  blk.1.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  20/ 363]               blk.2.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  21/ 363]                blk.2.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  22/ 363]                blk.2.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  23/ 363]                  blk.2.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  24/ 363]                blk.2.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  25/ 363]                  blk.2.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  26/ 363]             blk.2.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  27/ 363]                  blk.2.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  28/ 363]                  blk.2.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  29/ 363]               blk.3.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  30/ 363]                blk.3.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  31/ 363]                blk.3.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  32/ 363]                  blk.3.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  33/ 363]                blk.3.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  34/ 363]                  blk.3.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  35/ 363]             blk.3.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  36/ 363]                  blk.3.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  37/ 363]                  blk.3.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  38/ 363]               blk.4.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  39/ 363]                blk.4.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  40/ 363]                blk.4.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  41/ 363]                  blk.4.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  42/ 363]                blk.4.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  43/ 363]                  blk.4.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  44/ 363]             blk.4.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  45/ 363]                  blk.4.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  46/ 363]                  blk.4.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  47/ 363]               blk.5.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  48/ 363]                blk.5.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  49/ 363]                blk.5.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  50/ 363]                  blk.5.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  51/ 363]                blk.5.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  52/ 363]                  blk.5.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  53/ 363]             blk.5.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  54/ 363]                  blk.5.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  55/ 363]                  blk.5.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  56/ 363]                blk.6.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  57/ 363]                  blk.6.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  58/ 363]                  blk.6.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  59/ 363]             blk.6.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  60/ 363]                  blk.6.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  61/ 363]                  blk.6.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  62/ 363]              blk.10.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  63/ 363]               blk.10.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  64/ 363]               blk.10.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  65/ 363]                 blk.10.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  66/ 363]               blk.10.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  67/ 363]                 blk.10.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  68/ 363]            blk.10.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  69/ 363]                 blk.10.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  70/ 363]                 blk.10.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  71/ 363]              blk.11.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  72/ 363]               blk.11.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  73/ 363]               blk.11.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  74/ 363]                 blk.11.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  75/ 363]               blk.11.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  76/ 363]                 blk.11.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  77/ 363]            blk.11.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  78/ 363]                 blk.11.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  79/ 363]                 blk.11.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  80/ 363]              blk.12.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  81/ 363]               blk.12.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  82/ 363]               blk.12.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  83/ 363]                 blk.12.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  84/ 363]               blk.12.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  85/ 363]                 blk.12.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  86/ 363]            blk.12.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  87/ 363]                 blk.12.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  88/ 363]                 blk.12.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  89/ 363]              blk.13.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  90/ 363]               blk.13.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  91/ 363]               blk.13.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  92/ 363]                 blk.13.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  93/ 363]               blk.13.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  94/ 363]                 blk.13.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  95/ 363]            blk.13.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  96/ 363]                 blk.13.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  97/ 363]                 blk.13.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  98/ 363]               blk.6.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  99/ 363]                blk.6.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 100/ 363]                blk.6.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 101/ 363]               blk.7.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 102/ 363]                blk.7.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 103/ 363]                blk.7.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 104/ 363]                  blk.7.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 105/ 363]                blk.7.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 106/ 363]                  blk.7.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 107/ 363]             blk.7.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 108/ 363]                  blk.7.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 109/ 363]                  blk.7.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 110/ 363]               blk.8.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 111/ 363]                blk.8.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 112/ 363]                blk.8.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 113/ 363]                  blk.8.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 114/ 363]                blk.8.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 115/ 363]                  blk.8.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 116/ 363]             blk.8.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 117/ 363]                  blk.8.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 118/ 363]                  blk.8.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 119/ 363]               blk.9.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 120/ 363]                blk.9.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 121/ 363]                blk.9.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 122/ 363]                  blk.9.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 123/ 363]                blk.9.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 124/ 363]                  blk.9.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 125/ 363]             blk.9.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 126/ 363]                  blk.9.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 127/ 363]                  blk.9.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 128/ 363]              blk.14.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 129/ 363]               blk.14.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 130/ 363]               blk.14.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 131/ 363]                 blk.14.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 132/ 363]               blk.14.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 133/ 363]                 blk.14.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 134/ 363]            blk.14.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 135/ 363]                 blk.14.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 136/ 363]                 blk.14.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 137/ 363]              blk.15.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 138/ 363]               blk.15.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 139/ 363]               blk.15.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 140/ 363]                 blk.15.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 141/ 363]               blk.15.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 142/ 363]                 blk.15.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 143/ 363]            blk.15.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 144/ 363]                 blk.15.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 145/ 363]                 blk.15.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 146/ 363]              blk.16.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 147/ 363]               blk.16.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 148/ 363]               blk.16.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 149/ 363]                 blk.16.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 150/ 363]               blk.16.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 151/ 363]                 blk.16.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 152/ 363]            blk.16.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 153/ 363]                 blk.16.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 154/ 363]                 blk.16.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 155/ 363]              blk.17.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 156/ 363]               blk.17.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 157/ 363]               blk.17.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 158/ 363]                 blk.17.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 159/ 363]               blk.17.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 160/ 363]                 blk.17.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 161/ 363]            blk.17.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 162/ 363]                 blk.17.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 163/ 363]                 blk.17.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 164/ 363]              blk.18.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 165/ 363]               blk.18.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 166/ 363]               blk.18.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 167/ 363]                 blk.18.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 168/ 363]               blk.18.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 169/ 363]                 blk.18.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 170/ 363]            blk.18.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 171/ 363]                 blk.18.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 172/ 363]                 blk.18.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 173/ 363]              blk.19.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 174/ 363]               blk.19.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 175/ 363]               blk.19.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 176/ 363]                 blk.19.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 177/ 363]               blk.19.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 178/ 363]                 blk.19.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 179/ 363]            blk.19.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 180/ 363]                 blk.19.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 181/ 363]                 blk.19.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 182/ 363]              blk.20.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 183/ 363]               blk.20.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 184/ 363]               blk.20.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 185/ 363]                 blk.20.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 186/ 363]               blk.20.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 187/ 363]                 blk.20.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 188/ 363]            blk.20.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 189/ 363]                 blk.20.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 190/ 363]                 blk.20.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 191/ 363]                 blk.21.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 192/ 363]            blk.21.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 193/ 363]                 blk.21.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 194/ 363]                 blk.21.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 195/ 363]              blk.21.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 196/ 363]               blk.21.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 197/ 363]               blk.21.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 198/ 363]                 blk.21.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 199/ 363]               blk.21.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 200/ 363]              blk.22.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 201/ 363]               blk.22.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 202/ 363]               blk.22.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 203/ 363]                 blk.22.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 204/ 363]               blk.22.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 205/ 363]                 blk.22.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 206/ 363]            blk.22.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 207/ 363]                 blk.22.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 208/ 363]                 blk.22.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 209/ 363]              blk.23.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 210/ 363]               blk.23.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 211/ 363]               blk.23.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 212/ 363]                 blk.23.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 213/ 363]               blk.23.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 214/ 363]                 blk.23.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 215/ 363]            blk.23.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 216/ 363]                 blk.23.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 217/ 363]                 blk.23.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 218/ 363]              blk.24.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 219/ 363]               blk.24.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 220/ 363]               blk.24.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 221/ 363]                 blk.24.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 222/ 363]               blk.24.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 223/ 363]                 blk.24.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 224/ 363]            blk.24.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 225/ 363]                 blk.24.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 226/ 363]                 blk.24.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 227/ 363]              blk.25.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 228/ 363]               blk.25.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 229/ 363]               blk.25.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 230/ 363]                 blk.25.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 231/ 363]               blk.25.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 232/ 363]                 blk.25.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 233/ 363]            blk.25.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 234/ 363]                 blk.25.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 235/ 363]                 blk.25.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 236/ 363]              blk.26.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 237/ 363]               blk.26.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 238/ 363]               blk.26.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 239/ 363]                 blk.26.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 240/ 363]               blk.26.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 241/ 363]                 blk.26.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 242/ 363]            blk.26.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 243/ 363]                 blk.26.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 244/ 363]                 blk.26.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 245/ 363]              blk.27.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 246/ 363]               blk.27.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 247/ 363]               blk.27.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 248/ 363]                 blk.27.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 249/ 363]               blk.27.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 250/ 363]                 blk.27.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 251/ 363]            blk.27.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 252/ 363]                 blk.27.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 253/ 363]                 blk.27.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 254/ 363]               blk.28.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 255/ 363]                 blk.28.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 256/ 363]            blk.28.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 257/ 363]                 blk.28.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 258/ 363]                 blk.28.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 259/ 363]              blk.28.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 260/ 363]               blk.28.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 261/ 363]                 blk.28.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 262/ 363]               blk.28.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 263/ 363]              blk.29.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 264/ 363]               blk.29.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 265/ 363]               blk.29.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 266/ 363]                 blk.29.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 267/ 363]               blk.29.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 268/ 363]                 blk.29.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 269/ 363]            blk.29.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 270/ 363]                 blk.29.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 271/ 363]                 blk.29.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 272/ 363]              blk.30.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 273/ 363]               blk.30.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 274/ 363]               blk.30.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 275/ 363]                 blk.30.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 276/ 363]               blk.30.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 277/ 363]                 blk.30.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 278/ 363]            blk.30.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 279/ 363]                 blk.30.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 280/ 363]                 blk.30.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 281/ 363]              blk.31.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 282/ 363]               blk.31.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 283/ 363]               blk.31.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 284/ 363]                 blk.31.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 285/ 363]               blk.31.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 286/ 363]                 blk.31.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 287/ 363]            blk.31.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 288/ 363]                 blk.31.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 289/ 363]                 blk.31.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 290/ 363]              blk.32.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 291/ 363]               blk.32.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 292/ 363]               blk.32.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 293/ 363]                 blk.32.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 294/ 363]               blk.32.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 295/ 363]                 blk.32.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 296/ 363]            blk.32.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 297/ 363]                 blk.32.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 298/ 363]                 blk.32.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 299/ 363]              blk.33.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 300/ 363]               blk.33.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 301/ 363]               blk.33.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 302/ 363]                 blk.33.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 303/ 363]               blk.33.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 304/ 363]                 blk.33.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 305/ 363]            blk.33.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 306/ 363]                 blk.33.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 307/ 363]                 blk.33.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 308/ 363]              blk.34.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 309/ 363]               blk.34.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 310/ 363]               blk.34.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 311/ 363]                 blk.34.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 312/ 363]               blk.34.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 313/ 363]                 blk.34.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 314/ 363]            blk.34.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 315/ 363]                 blk.34.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 316/ 363]                 blk.34.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 317/ 363]               blk.35.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 318/ 363]                 blk.35.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 319/ 363]                 blk.35.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 320/ 363]            blk.35.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 321/ 363]                 blk.35.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 322/ 363]                 blk.35.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 323/ 363]                        output.weight - [ 5120, 32064,     1,     1], type =    f16, converting to q6_K .. size =   313.12 MiB ->   128.43 MiB\n",
            "[ 324/ 363]              blk.35.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 325/ 363]               blk.35.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 326/ 363]               blk.35.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 327/ 363]              blk.36.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 328/ 363]               blk.36.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 329/ 363]               blk.36.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 330/ 363]                 blk.36.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 331/ 363]               blk.36.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 332/ 363]                 blk.36.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 333/ 363]            blk.36.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 334/ 363]                 blk.36.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 335/ 363]                 blk.36.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 336/ 363]              blk.37.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 337/ 363]               blk.37.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 338/ 363]               blk.37.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 339/ 363]                 blk.37.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 340/ 363]               blk.37.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 341/ 363]                 blk.37.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 342/ 363]            blk.37.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 343/ 363]                 blk.37.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 344/ 363]                 blk.37.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 345/ 363]              blk.38.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 346/ 363]               blk.38.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 347/ 363]               blk.38.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 348/ 363]                 blk.38.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 349/ 363]               blk.38.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 350/ 363]                 blk.38.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 351/ 363]            blk.38.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 352/ 363]                 blk.38.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 353/ 363]                 blk.38.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 354/ 363]              blk.39.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 355/ 363]               blk.39.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 356/ 363]               blk.39.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 357/ 363]                 blk.39.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 358/ 363]               blk.39.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 359/ 363]                 blk.39.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 360/ 363]            blk.39.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 361/ 363]                 blk.39.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 362/ 363]                 blk.39.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 363/ 363]                   output_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "llama_model_quantize_internal: model size  = 26627.83 MB\n",
            "llama_model_quantize_internal: quant size  =  8013.98 MB\n",
            "\n",
            "main: quantize time = 519000.87 ms\n",
            "main:    total time = 519000.87 ms\n",
            "Unsloth: Conversion completed! Output location: ./kalinkov/Phi3_tailwindcss/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.F16.gguf:   0%|          | 0.00/27.9G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bec7b21e53b34788b1af1fc6daf22461"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/kalinkov/Phi3_tailwindcss\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/8.40G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3233866a7b8c4a7abb983b94c87b2c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/kalinkov/Phi3_tailwindcss\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bec7b21e53b34788b1af1fc6daf22461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_071b9704be194a6db44623ea6d5c9fcd",
              "IPY_MODEL_2731a96fb7344325a0576febcb8576b5",
              "IPY_MODEL_adff0e80933c482d8fa09fbfdb64f000"
            ],
            "layout": "IPY_MODEL_b7b48e0e692340d7b045172d2ea49541"
          }
        },
        "071b9704be194a6db44623ea6d5c9fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296157256bc1431f98b1c1b1245b7912",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fae14ad95cc54ee9903cc3b6e991023c",
            "value": "unsloth.F16.gguf:â€‡100%"
          }
        },
        "2731a96fb7344325a0576febcb8576b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb389cd0cba4b018cfa1cde3a86929f",
            "max": 27922053216,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9b9e824445f4f82a61c5d058539c800",
            "value": 27922053216
          }
        },
        "adff0e80933c482d8fa09fbfdb64f000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4762e7e5b5334353850132ae6b0e020b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d2b374598612450fb9d0f8facd5108d0",
            "value": "â€‡27.9G/27.9Gâ€‡[12:43&lt;00:00,â€‡46.5MB/s]"
          }
        },
        "b7b48e0e692340d7b045172d2ea49541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296157256bc1431f98b1c1b1245b7912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae14ad95cc54ee9903cc3b6e991023c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb389cd0cba4b018cfa1cde3a86929f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b9e824445f4f82a61c5d058539c800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4762e7e5b5334353850132ae6b0e020b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b374598612450fb9d0f8facd5108d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3233866a7b8c4a7abb983b94c87b2c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83424c5d88ab4f98a7b353baf3e31b75",
              "IPY_MODEL_cd1757d864d5469b9cc853a207efec85",
              "IPY_MODEL_681b0b39fe634b6b9b0edc5515b4699a"
            ],
            "layout": "IPY_MODEL_d1ef53f38bc14718ad89e85926debd40"
          }
        },
        "83424c5d88ab4f98a7b353baf3e31b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c0b4133bc7474ca474cdb709d1a7d5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_55b6ceff71524f70b437e212893b85a0",
            "value": "unsloth.Q4_K_M.gguf:â€‡100%"
          }
        },
        "cd1757d864d5469b9cc853a207efec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf5a0ef3697f45af86eee683dd05af4b",
            "max": 8404011616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_170335cc3c5345f3a8ad2d75cb436649",
            "value": 8404011616
          }
        },
        "681b0b39fe634b6b9b0edc5515b4699a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec2638df20f54e8b9d173fa082c252b1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3b4f15e869904922b4998d1984ef4f01",
            "value": "â€‡8.40G/8.40Gâ€‡[03:39&lt;00:00,â€‡34.8MB/s]"
          }
        },
        "d1ef53f38bc14718ad89e85926debd40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c0b4133bc7474ca474cdb709d1a7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b6ceff71524f70b437e212893b85a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5a0ef3697f45af86eee683dd05af4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170335cc3c5345f3a8ad2d75cb436649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec2638df20f54e8b9d173fa082c252b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4f15e869904922b4998d1984ef4f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c1c4ef3ead4fa2bd2f5dea7ece12fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_465188f321e7492ab924819325ddef7a",
              "IPY_MODEL_8f1cd6b2bb3a454c96767f91fb0dad0f",
              "IPY_MODEL_f591a6680b69466aa5ec3db8914cd680"
            ],
            "layout": "IPY_MODEL_756be3bdfa1b4f44ba61e770971c79f3"
          }
        },
        "465188f321e7492ab924819325ddef7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a1900f2b82424aab48c5da6837b67f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1dbdd06e729a4d4ab3a7277ebf9ea622",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "8f1cd6b2bb3a454c96767f91fb0dad0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4872f67c2d4055890591b72897f30d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6eec753bdb49485e91087bb453a1e262",
            "value": 2
          }
        },
        "f591a6680b69466aa5ec3db8914cd680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2843888970134722bc502878b497e9c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3a02131532c540079fe1684f70583d18",
            "value": "â€‡2/2â€‡[00:03&lt;00:00,â€‡â€‡1.90s/it]"
          }
        },
        "756be3bdfa1b4f44ba61e770971c79f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a1900f2b82424aab48c5da6837b67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbdd06e729a4d4ab3a7277ebf9ea622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad4872f67c2d4055890591b72897f30d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eec753bdb49485e91087bb453a1e262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2843888970134722bc502878b497e9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a02131532c540079fe1684f70583d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}